[package]
name = "whis-core"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
description = "Core library for whis voice-to-text functionality"

[dependencies]
anyhow.workspace = true
thiserror.workspace = true
tokio.workspace = true
serde.workspace = true
serde_json.workspace = true
reqwest = { workspace = true, features = ["blocking", "multipart", "json", "stream"] }
futures-util = "0.3"
cpal.workspace = true
hound = { workspace = true, optional = true }
arboard = { workspace = true, optional = true }
dotenvy.workspace = true
dirs = "6"
async-trait = "0.1"

# WebSocket for OpenAI Realtime API
tokio-tungstenite = { version = "0.28", features = ["rustls-tls-webpki-roots"], optional = true }
base64 = { version = "0.22", optional = true }

# Embedded MP3 encoder for mobile (no FFmpeg dependency)
mp3lame-encoder = { version = "0.2", optional = true }

# Real-time resampling to 16kHz (always enabled - benefits all providers)
rubato = "1.0"
audioadapter = "2.0"
audioadapter-buffers = "2.0"

# Voice Activity Detection using Silero VAD model
voice_activity_detector = { version = "0.2", optional = true }

# Local transcription via transcribe-rs (unified library for Whisper + Parakeet)
transcribe-rs = { version = "0.2.1", features = ["whisper", "parakeet"], optional = true }
minimp3 = { version = "0.6", optional = true }

# Archive extraction for Parakeet model downloads
tar = { version = "0.4", optional = true }
flate2 = { version = "1.0", optional = true }

# Temp files for Parakeet audio processing
tempfile = { version = "3", optional = true }

[features]
default = ["ffmpeg", "clipboard", "local-transcription", "vad", "realtime"]
# Desktop: use FFmpeg process for audio encoding and arboard for clipboard
ffmpeg = ["hound"]
clipboard = ["arboard"]
# Mobile: use embedded mp3lame encoder (no external process needed)
embedded-encoder = ["mp3lame-encoder"]
# Local transcription (Whisper + Parakeet via transcribe-rs)
local-transcription = ["minimp3", "transcribe-rs", "tar", "flate2", "tempfile"]
# Voice Activity Detection to skip silence during recording
vad = ["voice_activity_detector"]
# OpenAI Realtime API for streaming transcription
realtime = ["tokio-tungstenite", "base64"]
