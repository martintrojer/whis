//! Local transcription setup

use anyhow::{Result, anyhow};
use whis_core::{PostProcessor, Settings, TranscriptionProvider, model, ollama};

use super::interactive;
use super::post_processing::select_ollama_model;

#[cfg(feature = "local-transcription")]
use whis_core::model::{ModelType, ParakeetModel, WhisperModel};

/// Setup for fully local (on-device) transcription (full interactive wizard)
pub fn setup_local() -> Result<()> {
    let items = vec![
        "Parakeet (NVIDIA model)",
        "Whisper - Multiple sizes (OpenAI model)",
    ];

    let engine_choice = interactive::select("Which transcription engine?", &items, Some(0))? + 1;

    let (provider, model_path) = match engine_choice {
        1 => {
            // Parakeet setup - show available models
            let items: Vec<String> = ParakeetModel
                .models()
                .iter()
                .map(|model| {
                    let path = ParakeetModel.default_path(model.name);
                    let installed = if ParakeetModel.verify(&path) {
                        " [installed]"
                    } else {
                        ""
                    };
                    format!("{} - {}{}", model.name, model.description, installed)
                })
                .collect();

            let model_choice = interactive::select("Which Parakeet model?", &items, Some(0))?;
            let model = &ParakeetModel.models()[model_choice];
            let path = ParakeetModel.default_path(model.name);
            if !ParakeetModel.verify(&path) {
                interactive::info(&format!("Downloading {}...", model.name));
                model::download::download(&ParakeetModel, model.name, &path)?;
            }
            (TranscriptionProvider::LocalParakeet, path)
        }
        2 => {
            // Whisper setup - show available models
            let items: Vec<String> = WhisperModel
                .models()
                .iter()
                .map(|model| {
                    let path = WhisperModel.default_path(model.name);
                    let installed = if WhisperModel.verify(&path) {
                        " [installed]"
                    } else {
                        ""
                    };
                    format!("{} - {}{}", model.name, model.description, installed)
                })
                .collect();

            let model_choice = interactive::select("Which Whisper model?", &items, Some(2))?;
            let model = &WhisperModel.models()[model_choice];

            let path = WhisperModel.default_path(model.name);
            if !WhisperModel.verify(&path) {
                interactive::info(&format!("Downloading {}...", model.name));
                model::download::download(&WhisperModel, model.name, &path)?;
            }
            (TranscriptionProvider::LocalWhisper, path)
        }
        _ => unreachable!(),
    };

    let ollama_url = ollama::DEFAULT_OLLAMA_URL;

    // Check if Ollama is installed
    if !ollama::is_ollama_installed() {
        interactive::ollama_not_installed();
        return Err(anyhow!("Please install Ollama and run setup again"));
    }

    // Start Ollama if not running
    ollama::ensure_ollama_running(ollama_url)?;

    // Let user select model (shows installed + recommended options)
    let ollama_model = select_ollama_model(ollama_url, None)?;

    let mut settings = Settings::load();
    settings.transcription.provider = provider.clone();
    match &provider {
        TranscriptionProvider::LocalParakeet => {
            settings.transcription.local_models.parakeet_path =
                Some(model_path.to_string_lossy().to_string());
        }
        TranscriptionProvider::LocalWhisper => {
            settings.transcription.local_models.whisper_path =
                Some(model_path.to_string_lossy().to_string());
        }
        _ => {}
    }
    settings.post_processing.processor = PostProcessor::Ollama;
    settings.services.ollama.url = Some(ollama_url.to_string());
    settings.services.ollama.model = Some(ollama_model.clone());
    settings.save()?;

    interactive::info(&format!(
        "Configuration saved! Transcription: {}, Post-processing: Ollama ({})",
        provider.display_name(),
        ollama_model
    ));

    Ok(())
}

/// Streamlined local transcription setup (no post-processing config)
/// Used by the unified wizard
pub fn setup_transcription_local() -> Result<()> {
    let mut settings = Settings::load();

    // Determine current engine and show with [current] marker
    let current_engine = match settings.transcription.provider {
        TranscriptionProvider::LocalParakeet => Some(1),
        TranscriptionProvider::LocalWhisper => Some(2),
        _ => None,
    };

    let items: Vec<String> = vec![
        format!(
            "Parakeet{}",
            if current_engine == Some(1) {
                " [current]"
            } else {
                ""
            }
        ),
        format!(
            "Whisper{}",
            if current_engine == Some(2) {
                " [current]"
            } else {
                ""
            }
        ),
    ];
    let default = current_engine.map(|e| e - 1).unwrap_or(0);
    let engine_choice =
        interactive::select("Which transcription engine?", &items, Some(default))? + 1;

    let (provider, model_path) = match engine_choice {
        1 => {
            // Parakeet - show model options (matching Whisper pattern)

            // Get current model if any
            let current_model = settings
                .transcription
                .local_models
                .parakeet_path
                .as_ref()
                .and_then(|p| {
                    ParakeetModel
                        .models()
                        .iter()
                        .find(|m| ParakeetModel.default_path(m.name) == *p)
                        .map(|m| m.name)
                });

            // Build selection items
            let items: Vec<String> = ParakeetModel
                .models()
                .iter()
                .map(|model| {
                    let path = ParakeetModel.default_path(model.name);
                    let installed = if ParakeetModel.verify(&path) {
                        " [installed]"
                    } else {
                        ""
                    };
                    let current = if current_model == Some(model.name) {
                        " [current]"
                    } else {
                        ""
                    };
                    format!("{}{}{}", model.name, installed, current)
                })
                .collect();

            // Default to current model or first (recommended)
            let default_idx = current_model
                .and_then(|name| ParakeetModel.models().iter().position(|m| m.name == name))
                .unwrap_or(0);

            let model_choice =
                interactive::select("Which Parakeet model?", &items, Some(default_idx))?;
            let model = &ParakeetModel.models()[model_choice];

            let path = ParakeetModel.default_path(model.name);
            if !ParakeetModel.verify(&path) {
                model::download::download(&ParakeetModel, model.name, &path)?;
            }

            (TranscriptionProvider::LocalParakeet, path)
        }
        2 => {
            // Whisper - show model options
            // Get current model if any
            let current_model = settings
                .transcription
                .local_models
                .whisper_path
                .as_ref()
                .and_then(|p| {
                    WhisperModel
                        .models()
                        .iter()
                        .find(|m| WhisperModel.default_path(m.name) == *p)
                        .map(|m| m.name)
                });

            // Build selection items
            let items: Vec<String> = WhisperModel
                .models()
                .iter()
                .map(|model| {
                    let path = WhisperModel.default_path(model.name);
                    let installed = if WhisperModel.verify(&path) {
                        " [installed]"
                    } else {
                        ""
                    };
                    let current = if current_model == Some(model.name) {
                        " [current]"
                    } else {
                        ""
                    };
                    format!(
                        "{} - {}{}{}",
                        model.name, model.description, installed, current
                    )
                })
                .collect();

            // Default to current model or "small" (index 2)
            let default_idx = current_model
                .and_then(|name| WhisperModel.models().iter().position(|m| m.name == name))
                .unwrap_or(2);

            let model_choice =
                interactive::select("Which Whisper model?", &items, Some(default_idx))?;
            let model = &WhisperModel.models()[model_choice];

            let path = WhisperModel.default_path(model.name);
            if !WhisperModel.verify(&path) {
                interactive::info(&format!("Downloading {}...", model.name));
                model::download::download(&WhisperModel, model.name, &path)?;
            }

            (TranscriptionProvider::LocalWhisper, path)
        }
        _ => unreachable!(),
    };

    // Save transcription config
    settings.transcription.provider = provider.clone();
    match &provider {
        TranscriptionProvider::LocalParakeet => {
            settings.transcription.local_models.parakeet_path =
                Some(model_path.to_string_lossy().to_string());
        }
        TranscriptionProvider::LocalWhisper => {
            settings.transcription.local_models.whisper_path =
                Some(model_path.to_string_lossy().to_string());
        }
        _ => {}
    }
    settings.save()?;

    Ok(())
}
